<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Survey on </title>
    <link>https://phatcvo.github.io/tags/survey/</link>
    <description>Recent content in Survey on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Aug 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://phatcvo.github.io/tags/survey/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[RL] DRL-Basics Reinforcement Learning</title>
      <link>https://phatcvo.github.io/blog/drl-basicsrl/</link>
      <pubDate>Thu, 18 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/drl-basicsrl/</guid>
      <description>Basics Deep reinforcement learning (DRL) is the integration of deep learning methods, classically used in supervised or unsupervised learning contexts, with reinforcement learning (RL), a well-studied adaptive control method used in problems with delayed and partial feedback [@Sutton1998]. This section starts with the basics of RL, mostly to set the notations, and provides a quick overview of deep neural networks.
Table of contents Reinforcement learning and Markov Decision Process Policy and value functions Bellman equations Dynamic programming Monte-Carlo sampling Temporal Difference Eligibility traces Actor-critic architectures Function approximation Value-based function approximation Policy-based function approximation Reinforcement learning and Markov Decision Process RL methods apply to problems where an agent interacts with an environment in discrete time steps (@fig:agentenv).</description>
    </item>
    <item>
      <title>[Survey] Safe-Optimal Control for Motional Planning based on RL</title>
      <link>https://phatcvo.github.io/blog/safe-optimal-control-for-motional-planning-based-on-rl/</link>
      <pubDate>Wed, 18 May 2022 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/safe-optimal-control-for-motional-planning-based-on-rl/</guid>
      <description>Table of contents Optimal Control Dynamic Programming Linear Programming Tree-Based Planning Control Theory Model Predictive Control Safe Control Robust Control Risk-Averse Control Value-Constrained Control State-Constrained Control and Stability Uncertain Dynamical Systems Game Theory Sequential Learning Multi-Armed Bandit Best Arm Identification Black-box Optimization Reinforcement Learning Theory Value-based Policy-based Policy Gradient Actor-critic Derivative-free Model-based Exploration Hierarchy and Temporal Abstraction Partial Observability Transfer Multi-agent Representation Learning Offline Learning from Demonstrations Imitation Learning Applications to Autonomous Driving Inverse Reinforcement Learning Applications to Autonomous Driving Motion Planning Search Sampling Optimization Reactive Architecture and applications Optimal Control: Dynamic Programming (book) Dynamic Programming, Bellman R.</description>
    </item>
    <item>
      <title>[Survey] Survey of Motion Planning strategies</title>
      <link>https://phatcvo.github.io/blog/survey-of-motion-planning-strategies/</link>
      <pubDate>Fri, 18 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/survey-of-motion-planning-strategies/</guid>
      <description>Search and Heuristic A Note on Two Problems in Connexion with Graphs by Dijkstra A Formal Basis for the Heuristic Determination of Minimum Cost Paths by Hart On the complexity of admissible search algorithms by Martelli Heuristic Search Viewed as Path Finding in a Graph by Pohl R* Search by Likhachev abd Stentz Incremental A* by Koenig and Likhachev Lifelong planning A* by Koenig, Likhachev and Furcy Real-Time Adaptive A* by Koenig and Likhachev Multiheuristic A* by Aine, Swaminathan, Narayan, Hwang and Likhachev Linear Space Best-First Search Replanning Optimal and efficient path planning for partially-known environments by Stentz The Focussed D* Algorithm for Real-Time Replanning by Stentz Fast Replanning for Navigation in Unknown Terrain by Koenig and Likhachev Using Interpolation to Improve Path Planning: The Field D* Algorithm by Ferguson and Stentz Replanning with RRTs by Ferguson, Kalra and Stentz RRTX: Real-Time Motion Planning/Replanning for Environments with Unpredictable Obstacles by Otte and Frazzoli Real-time planning ARA*: Anytime A* with Provable Bounds on Sub-Optimality by Likhachev, Gordon and Thrun Anytime Dynamic A*: An Anytime, Replanning Algorithm by Likhachev, Ferguson, Gordon, Stentz and Thrun Anytime search in dynamic graphs by Likhachev, Ferguson, Gordon, Stentz and Thrun Anytime RRTs by Ferguson and Stentz RRTs Rapidly Exploring Random Trees: A new tool for path planning by Lavelle RRT-connect: An efficient approach to single-query path planning by Kuffner and Lavalle Sampling-based Algorithms for Optimal Motion Planning by Karaman and Frazolli Informed RRT*: Optimal Sampling-based Path Planning Focused via Direct Sampling of an Admissible Ellipsoidal Heuristic by Gammell, Srinivasa and Barfoot Batch Informed Trees (BIT*): Sampling-based Optimal Planning via the Heuristically Guided Search of Implicit Random Geometric Graphs by Gammell, Srinivasa and Barfoot Sampling-Based Path Planning on Configuration-Space Costmaps by Jaillet, Cortes and Simeon Addressing Cost-Space Chasms in Manipulation Planning by Berenson, Simeon and Srinivasa Optimal Kinodynamic Motion Planning using Incremental Sampling-based Methods by Karaman and Frazzoli Sampling-based Optimal Motion Planning for Non-holonomic Dynamical Systems by Karaman and Frazzoli State lattice-based planners Efficient constrained path planning via search in state lattices by Pivtoraiko and Kelly Differentially Constrained Mobile Robot Motion Planning in State Lattices by Pivtoraiko, Knepper and Kelly Kinodynamic motion planning with state lattice motion primitives by Pivtoraiko and Kelly Trajectory optimization The dynamic window approach to collision avoidance by Fox, Burgard and Thrun CHOMP: Covariant Hamiltonian optimization for motion planning by Zucker et al Timed elastic bands, Optimizing TEBs using sparse model, TEBs with distinctive topologies, TEBs for car-like robots by RÃ¶smann, Hoffmann and Bertram Trajectory generation for car-like robots On curves of minimal length with a constraint on average curvature, and with prescribed initial and terminal positions and tangents by Dubins Optimal paths for a car that goes both forwards and backwards by Reeds and Shepp Optimal Trajectories for Nonholonomic Mobile Robots by Soueres and Boissonnat Shortest paths synthesis for a car-like robot by Soueres and Laumond Smooth Local Path Planning for Autonomous Vehicles by Kanayama and Hartman Trajectory Generation for Car-like robots using cubic curvature polynomials by Nagy and Kelly Optimal Rough Terrain Trajectory Generation for Wheeled Mobile Robots by Howard and Kelly Planning for mobile robots A Guide to Heuristic-based Path Planning by Ferguson, Likhachev and Stentz Planning continuous-curvature paths for car-like robots by Scheuer and Fraichard Real Time Continuous Curvature Path Planner for an Autonomous Vehicle in an Urban Environment by Knowles Planning Long Dynamically Feasible Maneuvers for Autonomous Vehicles by Likhachev and Ferguson Autonomous Driving in Structured and Unstructured Environments by Kolski, Ferguson, Bellino and Siegwart Toward Reliable Off Road Autonomous Vehicles Operating in Challenging Environments by Kelly et al.</description>
    </item>
  </channel>
</rss>
