<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <link>https://phatcvo.github.io/</link>
    <description>Recent content on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 04 Nov 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://phatcvo.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[MPC] Linear Parameter-Varying - Model Predictive Control for Racing</title>
      <link>https://phatcvo.github.io/blog/lpv-mpp-mcp-for-racing/</link>
      <pubDate>Sat, 04 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/lpv-mpp-mcp-for-racing/</guid>
      <description>Planning and control for autonomous racing vehicles. This project allows you to solve the autonomous racing driving problem using advanced control theory. Particularly, here it is presented a collaborative work using optimal strategies. The Model Predictive Control (MPC) strategy is used online for computing the optimal trajectory maximizing vehicle velocity but also for computing the optimal control actions that make the vehicle to follow the computed references. All the algorithms are solved in real time employing the Operator Splitting Quadratic Program (OSQP) solver.</description>
    </item>
    <item>
      <title>[MPC] Learning Model Predictive Control for autonomous racing</title>
      <link>https://phatcvo.github.io/blog/learning-mpc-for-racing/</link>
      <pubDate>Fri, 03 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/learning-mpc-for-racing/</guid>
      <description>The Learning Model Predictive Control is a data-driven control framework developed at UCB in the MPC lab. In this example, we implemented the LMPC for the autonomous racing problem. The controller drives several laps on race track and it learns from experience how to drive faster.&#xA;In the above animation we see the vehicle&amp;rsquo;s closed-loop trajectory (in black) for laps 5, 30, 31 and 32. At each time instant the LMPC leverages forecast to plan the vehicle trajectory (in red) few seconds into the future.</description>
    </item>
    <item>
      <title>[MPC] Trajectory tracking with a quadrotor by LMPC</title>
      <link>https://phatcvo.github.io/blog/mpc-for-quadrotor/</link>
      <pubDate>Wed, 01 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/mpc-for-quadrotor/</guid>
      <description>The non-linear dynamics are linearized about a linearization trajectory $\bar{x}, \bar{u}$ while the quadrotor aims to track a different reference trajectory $x_{ref}, u_{ref}$.&#xA;The MPC controller solves the following optimization problem :&#xA;$$\begin{aligned} \min_{x_{1:N},u_{1:N-1}} \quad &amp;amp; \sum_{i=1}^{N-1} \bigg[ (x_i - x_{i,ref})^TQ(x_i - x_{i,ref}) + (u_i - u_{i,ref})^TR(u_i - u_{i,ref}) \bigg] + \frac{1}{2} (x_N - x_{N,ref})^TQ_f(x_N - x_{N,ref}) \\ \textrm{s.t.} \quad &amp;amp; x_1 = x_{\text{IC}} \\ &amp;amp; x_{k+1} = f(\bar{x}_k, \bar{u}_k) + \bigg[\frac{\partial f}{\partial x} \bigg|_{\bar{x}_k, \bar{u}_k} \bigg](x_k - \bar{x}_k) + \bigg[\frac{\partial f}{\partial u} \bigg|_{\bar{x}_k, \bar{u}_k} \bigg](u_k - \bar{u}_k) \quad \text{for } i = 1,2,\ldots,N-1 \\ &amp;amp; u_{min} \leq u_i \leq u_{max} \quad ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \text{for } i = 1,2,\ldots,N-1 \\ \end{aligned}$$</description>
    </item>
    <item>
      <title>[MPC] Model Predictive Control with discrete-time Control Barrier Functions</title>
      <link>https://phatcvo.github.io/blog/model-predictive-control-with-discrete-time-control-barrier-functions/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/model-predictive-control-with-discrete-time-control-barrier-functions/</guid>
      <description>The MPC-CBF optimization problem is given by:&#xA;$$\begin{aligned} \min_{u_{t: t+N-1 \mid t}} \quad &amp;amp; \frac{1}{2} \tilde{x}_N^T Q_x \tilde{x}_N+\sum_{k=0}^{N-1} \frac{1}{2} \tilde{x}_k^T Q_x \tilde{x}_k+\frac{1}{2} u_k^T Q_u u_k\\ \textrm{s.t.} \quad &amp;amp; x_{t+k+1 \mid t}=x_{t+k \mid t}+f\left(x_{t+k \mid t}, u_{t+k \mid t}\right) \cdot T_s, \quad k=0, . ., N-1,\\ &amp;amp; x_{\min } \leq x_{t+k \mid t} \leq x_{\max }, \quad k=0, \ldots, N-1,\\ &amp;amp; u_{\min } \leq u_{t+k \mid t} \leq u_{\max }, \quad k=0, \ldots, N-1, \\ &amp;amp; x_{t \mid t}=x_t, \\ &amp;amp; \Delta h\left(x_{t+k \mid t}, u_{t+k \mid t}\right) \geq-\gamma h\left(x_{t+k \mid t}\right), \quad k=0, \ldots, N-1 \\ \end{aligned}$$</description>
    </item>
    <item>
      <title>[LQR] iLQR/DDP algorithm for Non-linear trajectory optimization</title>
      <link>https://phatcvo.github.io/blog/iterative-linear-quadratic-regulator-and-differential-dynamic-programming/</link>
      <pubDate>Mon, 23 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/iterative-linear-quadratic-regulator-and-differential-dynamic-programming/</guid>
      <description>Differential Dynamic Programming (DDP) is an indirect method which optimizes over the unconstrained control-space. It uses a 2nd-order Taylor series approximation of the cost-to-go in Dynamic Programming (DP) to compute Newton steps on the control trajectory.&#xA;iLQR: Only keeps the first-order terms (Gauss-Newton approximation), which is similar to Riccati iterations, but accounts for the regularization and line-search required to handle the nonlinearity. DDP: Second-order terms included (Newton approximation). The iLQR/DDP controller solves the following finite-horizon optimization (Non-linear trajectory optimization) problem:</description>
    </item>
    <item>
      <title>[MPC] Nominal Nonlinear Model Predictive Control</title>
      <link>https://phatcvo.github.io/blog/nominal-nonlinear-model-predictive-control/</link>
      <pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/nominal-nonlinear-model-predictive-control/</guid>
      <description>Nonlinear model predictive control (NMPC) is a popular control method for multivariable control problems with important process constraints. The dynamic equation system is assumed to be given by differential algebraic equations (DAE). The code is mostly meant to be used as a way to verify the performance of more novel algorithms against an implementation more likely to be found in industry. It has the following features:&#xA;Cheap NMPC implementation for both receding and shrinking time horizons Parameter and state estimation using the UKF Efficient solution of nonlinear dynamic optimization formulation using automatic differentiation Always feasible due to soft-constraints Example This is a basic nonlinear model predictive control (NMPC) implementation in Python with soft constraints, which uses an Unscented Kalman filter for state estimation.</description>
    </item>
    <item>
      <title>[MPC] Linear Model Predictive Control</title>
      <link>https://phatcvo.github.io/blog/linear-model-predictive-control/</link>
      <pubDate>Fri, 23 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/linear-model-predictive-control/</guid>
      <description>Vehicle model linearization Vehicle model is&#xA;$$ \dot{x} = vcos(\phi)$$&#xA;$$ \dot{y} = vsin((\phi)$$&#xA;$$ \dot{v} = a$$&#xA;$$ \dot{\phi} = \frac{vtan(\delta)}{L}$$&#xA;State and Input vector:&#xA;$$ z = \begin{bmatrix} x-position \\\ y-position \\\ velocity \\\ yaw-angle\end{bmatrix} = \begin{bmatrix} x \\\ y \\\ v \\\ \phi\end{bmatrix} $$&#xA;$$u = \begin{bmatrix} acceleration \\ steering-angle \end{bmatrix} = \begin{bmatrix} a \\ \delta \end{bmatrix} $$&#xA;ODE is&#xA;$$ \dot{z} =\frac{\partial }{\partial z} z = f(z, u) = A&amp;rsquo;z+B&amp;rsquo;u$$</description>
    </item>
    <item>
      <title>[RL] DRL-Basics Reinforcement Learning</title>
      <link>https://phatcvo.github.io/blog/drl-basicsrl/</link>
      <pubDate>Thu, 18 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/drl-basicsrl/</guid>
      <description>Basics Deep reinforcement learning (DRL) is the integration of deep learning methods, classically used in supervised or unsupervised learning contexts, with reinforcement learning (RL), a well-studied adaptive control method used in problems with delayed and partial feedback [@Sutton1998]. This section starts with the basics of RL, mostly to set the notations, and provides a quick overview of deep neural networks.&#xA;Table of contents Reinforcement learning and Markov Decision Process Policy and value functions Bellman equations Dynamic programming Monte-Carlo sampling Temporal Difference Eligibility traces Actor-critic architectures Function approximation Value-based function approximation Policy-based function approximation Reinforcement learning and Markov Decision Process RL methods apply to problems where an agent interacts with an environment in discrete time steps (@fig:agentenv).</description>
    </item>
    <item>
      <title>[Survey] Safe-Optimal Control for Motional Planning based on RL</title>
      <link>https://phatcvo.github.io/blog/safe-optimal-control-for-motional-planning-based-on-rl/</link>
      <pubDate>Wed, 18 May 2022 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/safe-optimal-control-for-motional-planning-based-on-rl/</guid>
      <description>Table of contents Optimal Control Dynamic Programming Linear Programming Tree-Based Planning Control Theory Model Predictive Control Safe Control Robust Control Risk-Averse Control Value-Constrained Control State-Constrained Control and Stability Uncertain Dynamical Systems Game Theory Sequential Learning Multi-Armed Bandit Best Arm Identification Black-box Optimization Reinforcement Learning Theory Value-based Policy-based Policy Gradient Actor-critic Derivative-free Model-based Exploration Hierarchy and Temporal Abstraction Partial Observability Transfer Multi-agent Representation Learning Offline Learning from Demonstrations Imitation Learning Applications to Autonomous Driving Inverse Reinforcement Learning Applications to Autonomous Driving Motion Planning Search Sampling Optimization Reactive Architecture and applications Optimal Control: Dynamic Programming (book) Dynamic Programming, Bellman R.</description>
    </item>
    <item>
      <title>[Survey] Survey of Motion Planning strategies</title>
      <link>https://phatcvo.github.io/blog/survey-of-motion-planning-strategies/</link>
      <pubDate>Fri, 18 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/survey-of-motion-planning-strategies/</guid>
      <description>Search and Heuristic A Note on Two Problems in Connexion with Graphs by Dijkstra A Formal Basis for the Heuristic Determination of Minimum Cost Paths by Hart On the complexity of admissible search algorithms by Martelli Heuristic Search Viewed as Path Finding in a Graph by Pohl R* Search by Likhachev abd Stentz Incremental A* by Koenig and Likhachev Lifelong planning A* by Koenig, Likhachev and Furcy Real-Time Adaptive A* by Koenig and Likhachev Multiheuristic A* by Aine, Swaminathan, Narayan, Hwang and Likhachev Linear Space Best-First Search Replanning Optimal and efficient path planning for partially-known environments by Stentz The Focussed D* Algorithm for Real-Time Replanning by Stentz Fast Replanning for Navigation in Unknown Terrain by Koenig and Likhachev Using Interpolation to Improve Path Planning: The Field D* Algorithm by Ferguson and Stentz Replanning with RRTs by Ferguson, Kalra and Stentz RRTX: Real-Time Motion Planning/Replanning for Environments with Unpredictable Obstacles by Otte and Frazzoli Real-time planning ARA*: Anytime A* with Provable Bounds on Sub-Optimality by Likhachev, Gordon and Thrun Anytime Dynamic A*: An Anytime, Replanning Algorithm by Likhachev, Ferguson, Gordon, Stentz and Thrun Anytime search in dynamic graphs by Likhachev, Ferguson, Gordon, Stentz and Thrun Anytime RRTs by Ferguson and Stentz RRTs Rapidly Exploring Random Trees: A new tool for path planning by Lavelle RRT-connect: An efficient approach to single-query path planning by Kuffner and Lavalle Sampling-based Algorithms for Optimal Motion Planning by Karaman and Frazolli Informed RRT*: Optimal Sampling-based Path Planning Focused via Direct Sampling of an Admissible Ellipsoidal Heuristic by Gammell, Srinivasa and Barfoot Batch Informed Trees (BIT*): Sampling-based Optimal Planning via the Heuristically Guided Search of Implicit Random Geometric Graphs by Gammell, Srinivasa and Barfoot Sampling-Based Path Planning on Configuration-Space Costmaps by Jaillet, Cortes and Simeon Addressing Cost-Space Chasms in Manipulation Planning by Berenson, Simeon and Srinivasa Optimal Kinodynamic Motion Planning using Incremental Sampling-based Methods by Karaman and Frazzoli Sampling-based Optimal Motion Planning for Non-holonomic Dynamical Systems by Karaman and Frazzoli State lattice-based planners Efficient constrained path planning via search in state lattices by Pivtoraiko and Kelly Differentially Constrained Mobile Robot Motion Planning in State Lattices by Pivtoraiko, Knepper and Kelly Kinodynamic motion planning with state lattice motion primitives by Pivtoraiko and Kelly Trajectory optimization The dynamic window approach to collision avoidance by Fox, Burgard and Thrun CHOMP: Covariant Hamiltonian optimization for motion planning by Zucker et al Timed elastic bands, Optimizing TEBs using sparse model, TEBs with distinctive topologies, TEBs for car-like robots by Rösmann, Hoffmann and Bertram Trajectory generation for car-like robots On curves of minimal length with a constraint on average curvature, and with prescribed initial and terminal positions and tangents by Dubins Optimal paths for a car that goes both forwards and backwards by Reeds and Shepp Optimal Trajectories for Nonholonomic Mobile Robots by Soueres and Boissonnat Shortest paths synthesis for a car-like robot by Soueres and Laumond Smooth Local Path Planning for Autonomous Vehicles by Kanayama and Hartman Trajectory Generation for Car-like robots using cubic curvature polynomials by Nagy and Kelly Optimal Rough Terrain Trajectory Generation for Wheeled Mobile Robots by Howard and Kelly Planning for mobile robots A Guide to Heuristic-based Path Planning by Ferguson, Likhachev and Stentz Planning continuous-curvature paths for car-like robots by Scheuer and Fraichard Real Time Continuous Curvature Path Planner for an Autonomous Vehicle in an Urban Environment by Knowles Planning Long Dynamically Feasible Maneuvers for Autonomous Vehicles by Likhachev and Ferguson Autonomous Driving in Structured and Unstructured Environments by Kolski, Ferguson, Bellino and Siegwart Toward Reliable Off Road Autonomous Vehicles Operating in Challenging Environments by Kelly et al.</description>
    </item>
    <item>
      <title></title>
      <link>https://phatcvo.github.io/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/readme/</guid>
      <description>Create content hugo new content/blog/name-post.md. Build hugo -&amp;gt; Test Locally hugo server -D. Commit to GitHub&#xA;git init git add . git commit -m &amp;#34;add&amp;#34; git branch -M main git push -f origin main Pull to sync git pull origin main&#xA;Note: (debug) githib/yourwebsite-repository -&amp;gt; action tab -&amp;gt; delete Hugo workflow -&amp;gt; Settings tab -&amp;gt; Pages tab - &amp;gt; Create Hugo workflow</description>
    </item>
    <item>
      <title>[Book] Clean Code - Chapter 1</title>
      <link>https://phatcvo.github.io/blog/clean-code-chapter-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/clean-code-chapter-1/</guid>
      <description>CHƯƠNG 1: CODE SẠCH Bạn đang đọc quyển sách này vì hai lý do. Thứ nhất, bạn là một lập trình viên. Thứ hai, bạn muốn trở thành một lập trình viên giỏi. Tuyệt vời! Chúng tôi cần lập trình viên giỏi.&#xA;Đây là một quyển sách nói về cách để bạn code tốt hơn, và nó chứa đầy code. Chúng ta sẽ xem xét code từ nhiều phương diện, từ trên xuống dưới, từ dưới lên trên, và từ trong ra ngoài.</description>
    </item>
    <item>
      <title>[Book] Clean Code - Chapter 10</title>
      <link>https://phatcvo.github.io/blog/clean-code-chapter-10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/clean-code-chapter-10/</guid>
      <description>Lớp bởi Jeff Langr Cho đến nay trong cuốn sách này, chúng ta đã tập trung vào cách viết tốt các dòng và khối mã. Đi sâu vào thành phần thích hợp của các chức năng và cách chúng tương tác với nhau. Nhưng sau tất cả, sự chú ý đến tính biểu đạt của các câu lệnh và các chức năng mà chúng bao gồm, vẫn chưa có mã sạch cho đến khi quan tâm đến các cấp tổ chức mã cao hơn.</description>
    </item>
    <item>
      <title>[Book] Clean Code - Chapter 11</title>
      <link>https://phatcvo.github.io/blog/clean-code-chapter-11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/clean-code-chapter-11/</guid>
      <description>Hệ thống bởi Tiến sĩ Kevin Dean Wampler “Loại bỏ sự phức tạp. Nó bòn rút sự sống của các nhà phát triển, khiến các sản phẩm khó lên kế hoạch, xây dựng và thử nghiệm ”. —Ray Ozzie, CTO, Microsoft Corporation&#xA;Bạn sẽ xây dựng một thành phố như thế nào? Bạn có thể tự quản lý tất cả các chi tiết? Chắc là không. Ngay cả việc quản lý một thành phố hiện tại cũng là quá nhiều đối với một người.</description>
    </item>
    <item>
      <title>[Book] Clean Code - Chapter 2</title>
      <link>https://phatcvo.github.io/blog/clean-code-chapter-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/clean-code-chapter-2/</guid>
      <description>CHƯƠNG 2: NHỮNG CÁI TÊN RÕ NGHĨA - Viết bởi Tim Ottinger&#xA;Giới thiệu Những cái tên có ở khắp mọi nơi trong phần mềm. Chúng ta đặt tên cho các biến, các hàm, các đối số, các lớp và các gói của chúng ta. Chúng ta đặt tên cho những file mã nguồn và thư mục chứa chúng. Chúng ta đặt tên cho những file *.jar, file *.war,... Chúng ta đặt tên và đặt tên.</description>
    </item>
    <item>
      <title>[Book] Clean Code - Chapter 3</title>
      <link>https://phatcvo.github.io/blog/clean-code-chapter-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/clean-code-chapter-3/</guid>
      <description>CHƯƠNG 3: HÀM Trong những buổi đầu của việc lập trình, chúng tôi soạn thảo các hệ thống câu lệnh và các chương trình con. Sau đó, trong thời đại của Fortran và PL/1, chúng tôi soạn thảo các hệ thống chương trình, chương trình con, và các hàm. Ngày nay, chỉ còn các hàm là tồn tại. Các hàm là những viên gạch xây dựng nên chương trình. Và chương này sẽ giúp bạn tạo nên những viên gạch chắc chắn cho chương trình của bạn.</description>
    </item>
    <item>
      <title>[Book] Clean Code - Chapter 4</title>
      <link>https://phatcvo.github.io/blog/clean-code-chapter-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/clean-code-chapter-4/</guid>
      <description>CHƯƠNG 4: CƠM-MỪN &amp;ldquo;Đừng biến đống code gớm ghiếc của bạn thành comment - hãy viết lại nó&amp;rdquo;&#xA;- Brian W. Kernighan and P. J. Plaugher&#xA;Không gì hữu ích bằng một comment được đặt đúng chổ. Không gì có thể làm lộn xộn đống code của bạn, ngoại trừ những comment ngu xuẩn và dối trá. Và không gì có thể gây nguy hiểm bằng một comment cộc lốc từ đời nào và lại không đúng sự thật.</description>
    </item>
    <item>
      <title>[Book] Clean Code - Chapter 5</title>
      <link>https://phatcvo.github.io/blog/clean-code-chapter-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/clean-code-chapter-5/</guid>
      <description>CHƯƠNG 5: ĐỊNH DẠNG CODE Khi mọi người tiến hành bảo dưỡng dự án, chúng tôi muốn họ ấn tượng bởi sự gọn gàng, nhất quán, và chú ý đến từng chi tiết mà chúng tôi đã tạo ra. Chúng tôi muốn họ choáng ngợp bởi sự ngăn nắp. Chúng tôi muốn họ phải bất ngờ khi xem qua các module. Chúng tôi muốn họ nhận thức được rằng chúng tôi chuyên nghiệp, và đây là sản phẩm được tạo ra bởi chuyên gia.</description>
    </item>
    <item>
      <title>[Book] Clean Code - Chapter 6</title>
      <link>https://phatcvo.github.io/blog/clean-code-chapter-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/clean-code-chapter-6/</guid>
      <description>CHƯƠNG 6: ĐỐI TƯỢNG VÀ CẤU TRÚC DỮ LIỆU Chúng tôi có lý do khi muốn giữ các biến là private. Chúng tôi không muốn ai đó phụ thuộc vào chúng. Chúng tôi muốn giữ sự tự do để thay đổi kiểu (dữ liệu) hoặc thực hiện các hành động tùy biến. Nhưng sau đó thì sao? Rất nhiều lập trình viên tự động thêm getter và setter vào class của họ, chẳng khác gì thay đổi các biến private thành public.</description>
    </item>
    <item>
      <title>[Book] Clean Code - Chapter 7</title>
      <link>https://phatcvo.github.io/blog/clean-code-chapter-7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/clean-code-chapter-7/</guid>
      <description>Chaper 07: Xử lý lỗi Michael Feathers Có vẻ kỳ lạ khi lại có một phần về xử lý lỗi trong một cuốn sách về mã sạch. Xử lý lỗi chỉ là một trong những việc mà tất cả chúng ta phải làm khi lập trình. Đầu vào có thể bất thường và thiết bị có thể bị lỗi. Nói tóm lại, mọi thứ đều có thể xảy ra sai sót, và khi chúng xảy ra, chúng ta với tư cách là người lập trình có trách nhiệm đảm bảo rằng mã của chúng ta thực hiện những gì nó cần làm.</description>
    </item>
    <item>
      <title>[Book] Clean Code - Chapter 8</title>
      <link>https://phatcvo.github.io/blog/clean-code-chapter-8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/clean-code-chapter-8/</guid>
      <description>Ranh giới bởi James Grenning Chúng ta hiếm khi kiểm soát hoàn toàn các phần mềm trong hệ thống của mình. Đôi khi chúng ta mua gói của bên thứ ba hoặc sử dụng mã nguồn mở. Những lần khác, chúng ta phụ thuộc vào các nhóm trong công ty để sản xuất các thành phần hoặc hệ thống con. Bằng cách nào đó, chúng ta phải tích hợp các mã ngoài này với mã riêng của chúng ta một cách rõ ràng.</description>
    </item>
    <item>
      <title>[Book] Clean Code - Chapter 9</title>
      <link>https://phatcvo.github.io/blog/clean-code-chapter-9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://phatcvo.github.io/blog/clean-code-chapter-9/</guid>
      <description>Kiểm tra đơn vị Nghề của chúng ta đã đi một chặng đường dài trong mười năm qua. Năm 1997, không ai nghe nói về Phát triển theo hướng kiểm tra. Đối với đại đa số nhà phát triển, các bài kiểm tra đơn vị là những đoạn mã ngắn được viết để đảm bảo chương trình “hoạt động”. Chúng tôi sẽ cẩn thận viết các lớp và phương thức của mình rồi sau đó tạo ra một số mã đặc biệt để kiểm tra chúng.</description>
    </item>
  </channel>
</rss>
