<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <link>https://phatcv.vercel.app/</link>
    <description>Recent content on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Sep 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://phatcv.vercel.app/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Model-Predictive Control</title>
      <link>https://phatcv.vercel.app/blog/eq/</link>
      <pubDate>Fri, 23 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://phatcv.vercel.app/blog/eq/</guid>
      <description>$$x = {-b \pm \sqrt{b^2-4ac} \over 2a}$$</description>
    </item>
    
    <item>
      <title>Model-Predictive Control</title>
      <link>https://phatcv.vercel.app/blog/post_1/</link>
      <pubDate>Fri, 23 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://phatcv.vercel.app/blog/post_1/</guid>
      <description>Vehicle model linearization Vehicle model is $$ \dot{x} = vcos(\phi)$$
$$ \dot{y} = vsin((\phi)$$
$$ \dot{v} = a$$
$$ \dot{\phi} = \frac{vtan(\delta)}{L}$$
State and Input vector:
$$ z = [x, y, v,\phi] $$
$$u = [a, \delta]$$
x: x-position; y:y-position; v:velocity; φ: yaw angle; a: acceleration; δ: steering angle
ODE is
$$ \dot{z} =\frac{\partial }{\partial z} z = f(z, u) = A&amp;rsquo;z+B&amp;rsquo;u$$
where
$$ A&amp;rsquo; = \begin{bmatrix} \frac{\partial }{\partial x}vcos(\phi) &amp;amp; \frac{\partial }{\partial y}vcos(\phi) &amp;amp; \frac{\partial }{\partial v}vcos(\phi) &amp;amp; \frac{\partial }{\partial \phi}vcos(\phi)\ \frac{\partial }{\partial x}vsin(\phi) &amp;amp; \frac{\partial }{\partial y}vsin(\phi) &amp;amp; \frac{\partial }{\partial v}vsin(\phi) &amp;amp; \frac{\partial }{\partial \phi}vsin(\phi)\ \frac{\partial }{\partial x}a&amp;amp; \frac{\partial }{\partial y}a&amp;amp; \frac{\partial }{\partial v}a&amp;amp; \frac{\partial }{\partial \phi}a\ \frac{\partial }{\partial x}\frac{vtan(\delta)}{L}&amp;amp; \frac{\partial }{\partial y}\frac{vtan(\delta)}{L}&amp;amp; \frac{\partial }{\partial v}\frac{vtan(\delta)}{L}&amp;amp; \frac{\partial }{\partial \phi}\frac{vtan(\delta)}{L} \end{bmatrix} = \begin{bmatrix} 0 &amp;amp; 0 &amp;amp; cos(\bar{\phi}) &amp;amp; -\bar{v}sin(\bar{\phi})\ 0 &amp;amp; 0 &amp;amp; sin(\bar{\phi}) &amp;amp; \bar{v}cos(\bar{\phi}) \ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \ 0 &amp;amp; 0 &amp;amp;\frac{tan(\bar{\delta})}{L} &amp;amp; 0 \ \end{bmatrix} $$</description>
    </item>
    
    <item>
      <title>ROS Motion Planning</title>
      <link>https://phatcv.vercel.app/blog/post_3/</link>
      <pubDate>Wed, 18 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://phatcv.vercel.app/blog/post_3/</guid>
      <description>ROS Motion Planning Motion planning is a computational problem to find a sequence of valid configurations that moves the object from the source to destination. Generally, it includes Path Searching and Trajectory Optimization.
Path Searching: Based on path constraints, e.g. obstacles, it searches an optimal path sequence for the robot to travel without conflicts between source and destination.
Trajectory Planning: Based on the kinematics, dynamics and obstacles, it optimizes a motion state trajectory from the source to destination according to the path sequence.</description>
    </item>
    
    <item>
      <title>Safe-Optimal Control for Motional Planning based on RL</title>
      <link>https://phatcv.vercel.app/blog/post_2/</link>
      <pubDate>Wed, 18 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://phatcv.vercel.app/blog/post_2/</guid>
      <description>Table of contents Optimal Control Dynamic Programming Linear Programming Tree-Based Planning Control Theory Model Predictive Control Safe Control Robust Control Risk-Averse Control Value-Constrained Control State-Constrained Control and Stability Uncertain Dynamical Systems Game Theory Sequential Learning Multi-Armed Bandit Best Arm Identification Black-box Optimization Reinforcement Learning Theory Value-based Policy-based Policy Gradient Actor-critic Derivative-free Model-based Exploration Hierarchy and Temporal Abstraction Partial Observability Transfer Multi-agent Representation Learning Offline Learning from Demonstrations Imitation Learning Applications to Autonomous Driving Inverse Reinforcement Learning Applications to Autonomous Driving Motion Planning Search Sampling Optimization Reactive Architecture and applications Optimal Control: Dynamic Programming (book) Dynamic Programming, Bellman R.</description>
    </item>
    
  </channel>
</rss>
